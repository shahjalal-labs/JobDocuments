### ğŸ“‹ LLM TASK INSTRUCTIONS  
ğŸ“… Date: 2025-08-09
You are an expert job formatter.

---

#### ğŸ”§ Your Task:
1. Read and **explain the job** in human-friendly detail: role, company, location, compensation, type.  
2. **Convert all currencies to BDT and monthly**, keeping the original .  
3. **Convert timezones to GMT+6** (Dhaka), keeping the original.  
4. **Categorize stack** into:  
   - âœ… Required stack  
   - ğŸ”§ Mentioned/optional stack  
5. **Explain how to apply**, if mentioned (email, form, DM, etc.)  
7. My skills are: ["JavaScript", "Markdown", "Lua", "React", "React Router", "TanStack Query", "Tailwind CSS", "Node.js", "Express.js", "MongoDB", "Firebase", "JWT", "Surge", "Netlify", "Figma", "Neovim", "Tmux", "Zsh", "Kitty", "SurfingKeys", "Hyprland", "EndeavourOS", "HTML", "CSS"]
8. I have hands on practice with professional course and projectsmore than 5
9. so clarify how much the job requirement match with me 
10. Iâ€™ve completed 5+ hands-on real-world MERN projects, built with scalable architecture and CLI workflow.  
    Here are my best examples:

      ğŸŒ DeshGuide â€“ Tourism Management System  
    ğŸ”— Live: https://deshguide.surge.sh

    ğŸ’¼ WorkElevate â€“ Job Portal  
    ğŸ”— Live: https://workelevate.surge.sh

    ğŸ§‘â€ğŸ³ FlavorBook â€“ Recipe Sharing + Marketplace  
    ğŸ”— Live: https://flavor-book.surge.sh

    ğŸ“ EduVerse â€“ Group Assignment Platform  
    ğŸ”— Live: https://edu-verse.surge.sh

    ğŸ–¥ï¸ My Portfolio (v2)  
    ğŸ”— Live: https://shahjalal-labs.surge.sh
    ğŸš€ GitHub Profile: https://github.com/shahjalal-labs

11. Based on the job description, rate how well my skills match this job:  
    - % match or keyword overlap  
    - Any strong alignment you find  
    - Mention projects from my GitHub that reflect this

12. Give a match score out of 10 with a short reason.

13. Tell me if the job supports or restricts my Linux-first terminal workflow (Hyprland, Tmux, Neovim, Zsh, Kitty, etc.)

14. If the job includes frontend/backend stacks, suggest any gaps I should fill, e.g., missing skill or tool.

15. If the company is named, provide:  
    - Quick company summary (size, country, sector)  
    - If remote, confirm timezone overlap with Bangladesh

16. If any requirement looks vague, confusing, or a red flag, highlight it.

17. **Then generate a README-style markdown summary** using this exact structure:
```markdown
---
### 38.04 `ğŸ¢ Company Name â€” Job Title - (onsite/remote)- date - bdt salary`

<pre><code>
ğŸ“… Applied On: foramt: 31/12/25 2025-08-09ğŸ’° Stipend/Salary : Original â‰ˆ Converted BDT / Monthly
â° Hours: Bangladesh Time â†’ Original Timezone
ğŸ§° Stack: Required Tech Stack
âŒ Lack Stack: It will be  Dynamic not static â€“ Based on Job Requirements: For your example added: mysql, postgres, redis, docker, nginx, aws, gcp, azure, firebase, netlify, surge, figma, sketch, etc.
ğŸ“† Interview Date: (If known or write "Not yet scheduled")
ğŸŒ Location: Full Location + Timezone
ğŸ§­ Platform: Source or Application method
â³ Status: ğŸŸ¡ Pending or other
ğŸ“  Follow-Up way:  career@remoteoffice.io
</code></pre>

ğŸ”— [Company Website](url) `url` <br />
ğŸ”— [Job Link](link) `link: first 30 chars...`
---

Job Description

This is a remote position.


Job Title: Back-End Software Engineer
Location: Remote
Team: AI Infrastructure & Engineering
Employment Type: Full-Time
*Superstaffed.ai is part of Remote Workmate PTY LTD

About the Role:
Weâ€™re looking for a Back-End Software Engineer to architect and build high-performance infrastructure behind our AI-powered applications. This role sits at the intersection of software engineering and machine learning infrastructure. Youâ€™ll lead the development of APIs, vector databases, and scalable microservices that serve real-time intelligent responses using models like OpenAI and Hugging Face.

Youâ€™ll thrive here if youâ€™re an autonomous problem solver who optimizes systems for speed, reliability, and costâ€”someone who thinks in automation and ships measurable results fast.
Ready to Apply?

You can begin the application process right away by completing a short, self-paced video interview with â€œAlex,â€ our AI interviewer. This helps us fairly assess your experience, communication style, and fit for the role.

Start the interview here: https://interviews.apriora.ai/remoteworkmate-back-end-software-engineer-4rxg
*Note: Applications without a video interview will not be processed.

Responsibilities:

    Design and maintain APIs for AI-powered features (FastAPI, Flask)

    Integrate and fine-tune LLMs (OpenAI, Hugging Face, LangChain)

    Build pipelines for vector embeddings, semantic search, and RAG

    Optimize back-end systems for latency, scalability, and cost

    Collaborate with ML engineers to deploy and monitor inference systems

    Implement observability (Sentry, Prometheus, Grafana) for debugging

    Manage CI/CD and infrastructure-as-code (Docker, GitHub Actions, Terraform)

    Own full product verticals from API to deployment


Requirements:

    3+ years in back-end/API engineering (Python, FastAPI/Flask)

    Experience with PostgreSQL, Docker, and containerized development

    Proven use of OpenAI APIs, Hugging Face, LangChain, or Transformers

    Familiar with vector databases like Pinecone, Qdrant, or Weaviate

    Experience in CI/CD, observability, and monitoring systems

    Bonus: Knowledge of asyncio, aiohttp, k8s, or serverless environments

    Strong communication, async-first documentation, and remote collaboration skills



Performance Milestones:
First 30 Days


    Set up staging and dev environments

    Review codebase and system architecture

    Deploy test API integrating a basic OpenAI or HF model

By Day 60

    Launch a production-ready AI feature (e.g., vector store or RAG endpoint)

    Improve model response latency by 30â€“50%

    Implement >80% test coverage

By Day 90

    Own back-end infrastructure for a product line

    Reduce compute costs through caching/async strategies

    Contribute to LLM scaling roadmap


Success Metrics (KPOs):

    API latency < 500ms on average

    Uptime â‰¥ 99.5% on core services

    Test coverage > 85%

    1â€“2 production deployments per week

    LLM inference â‰¤ 3s with retries/failure handling


Tech Stack:

    AI Platforms: OpenAI, Hugging Face, LangChain

    Frameworks: FastAPI, Flask, SQLAlchemy

    Databases: PostgreSQL, Redis, Pinecone, Qdrant

    DevOps: Docker, GitHub Actions, Terraform

    Monitoring: Prometheus, Grafana, Sentry

    Collaboration: Slack, Notion, ChatGPT



    View all jobs Visit website 

Powered by


```
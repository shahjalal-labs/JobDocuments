### 📋 LLM TASK INSTRUCTIONS  
📅 Date: 2025-08-09
You are an expert job formatter.

---

#### 🔧 Your Task:
1. Read and **explain the job** in human-friendly detail: role, company, location, compensation, type.  
2. **Convert all currencies to BDT and monthly**, keeping the original .  
3. **Convert timezones to GMT+6** (Dhaka), keeping the original.  
4. **Categorize stack** into:  
   - ✅ Required stack  
   - 🔧 Mentioned/optional stack  
5. **Explain how to apply**, if mentioned (email, form, DM, etc.)  
7. My skills are: ["JavaScript", "Markdown", "Lua", "React", "React Router", "TanStack Query", "Tailwind CSS", "Node.js", "Express.js", "MongoDB", "Firebase", "JWT", "Surge", "Netlify", "Figma", "Neovim", "Tmux", "Zsh", "Kitty", "SurfingKeys", "Hyprland", "EndeavourOS", "HTML", "CSS"]
8. I have hands on practice with professional course and projectsmore than 5
9. so clarify how much the job requirement match with me 
10. I’ve completed 5+ hands-on real-world MERN projects, built with scalable architecture and CLI workflow.  
    Here are my best examples:

      🌐 DeshGuide – Tourism Management System  
    🔗 Live: https://deshguide.surge.sh

    💼 WorkElevate – Job Portal  
    🔗 Live: https://workelevate.surge.sh

    🧑‍🍳 FlavorBook – Recipe Sharing + Marketplace  
    🔗 Live: https://flavor-book.surge.sh

    🎓 EduVerse – Group Assignment Platform  
    🔗 Live: https://edu-verse.surge.sh

    🖥️ My Portfolio (v2)  
    🔗 Live: https://shahjalal-labs.surge.sh
    🚀 GitHub Profile: https://github.com/shahjalal-labs

11. Based on the job description, rate how well my skills match this job:  
    - % match or keyword overlap  
    - Any strong alignment you find  
    - Mention projects from my GitHub that reflect this

12. Give a match score out of 10 with a short reason.

13. Tell me if the job supports or restricts my Linux-first terminal workflow (Hyprland, Tmux, Neovim, Zsh, Kitty, etc.)

14. If the job includes frontend/backend stacks, suggest any gaps I should fill, e.g., missing skill or tool.

15. If the company is named, provide:  
    - Quick company summary (size, country, sector)  
    - If remote, confirm timezone overlap with Bangladesh

16. If any requirement looks vague, confusing, or a red flag, highlight it.

17. **Then generate a README-style markdown summary** using this exact structure:
```markdown
---
### 38.04 `🏢 Company Name — Job Title - (onsite/remote)- date - bdt salary`

<pre><code>
📅 Applied On: foramt: 31/12/25 2025-08-09💰 Stipend/Salary : Original ≈ Converted BDT / Monthly
⏰ Hours: Bangladesh Time → Original Timezone
🧰 Stack: Required Tech Stack
❌ Lack Stack: It will be  Dynamic not static – Based on Job Requirements: For your example added: mysql, postgres, redis, docker, nginx, aws, gcp, azure, firebase, netlify, surge, figma, sketch, etc.
📆 Interview Date: (If known or write "Not yet scheduled")
🌐 Location: Full Location + Timezone
🧭 Platform: Source or Application method
⏳ Status: 🟡 Pending or other
📞  Follow-Up way:  career@remoteoffice.io
</code></pre>

🔗 [Company Website](url) `url` <br />
🔗 [Job Link](link) `link: first 30 chars...`
---

Job Description

This is a remote position.


Job Title: Back-End Software Engineer
Location: Remote
Team: AI Infrastructure & Engineering
Employment Type: Full-Time
*Superstaffed.ai is part of Remote Workmate PTY LTD

About the Role:
We’re looking for a Back-End Software Engineer to architect and build high-performance infrastructure behind our AI-powered applications. This role sits at the intersection of software engineering and machine learning infrastructure. You’ll lead the development of APIs, vector databases, and scalable microservices that serve real-time intelligent responses using models like OpenAI and Hugging Face.

You’ll thrive here if you’re an autonomous problem solver who optimizes systems for speed, reliability, and cost—someone who thinks in automation and ships measurable results fast.
Ready to Apply?

You can begin the application process right away by completing a short, self-paced video interview with “Alex,” our AI interviewer. This helps us fairly assess your experience, communication style, and fit for the role.

Start the interview here: https://interviews.apriora.ai/remoteworkmate-back-end-software-engineer-4rxg
*Note: Applications without a video interview will not be processed.

Responsibilities:

    Design and maintain APIs for AI-powered features (FastAPI, Flask)

    Integrate and fine-tune LLMs (OpenAI, Hugging Face, LangChain)

    Build pipelines for vector embeddings, semantic search, and RAG

    Optimize back-end systems for latency, scalability, and cost

    Collaborate with ML engineers to deploy and monitor inference systems

    Implement observability (Sentry, Prometheus, Grafana) for debugging

    Manage CI/CD and infrastructure-as-code (Docker, GitHub Actions, Terraform)

    Own full product verticals from API to deployment


Requirements:

    3+ years in back-end/API engineering (Python, FastAPI/Flask)

    Experience with PostgreSQL, Docker, and containerized development

    Proven use of OpenAI APIs, Hugging Face, LangChain, or Transformers

    Familiar with vector databases like Pinecone, Qdrant, or Weaviate

    Experience in CI/CD, observability, and monitoring systems

    Bonus: Knowledge of asyncio, aiohttp, k8s, or serverless environments

    Strong communication, async-first documentation, and remote collaboration skills



Performance Milestones:
First 30 Days


    Set up staging and dev environments

    Review codebase and system architecture

    Deploy test API integrating a basic OpenAI or HF model

By Day 60

    Launch a production-ready AI feature (e.g., vector store or RAG endpoint)

    Improve model response latency by 30–50%

    Implement >80% test coverage

By Day 90

    Own back-end infrastructure for a product line

    Reduce compute costs through caching/async strategies

    Contribute to LLM scaling roadmap


Success Metrics (KPOs):

    API latency < 500ms on average

    Uptime ≥ 99.5% on core services

    Test coverage > 85%

    1–2 production deployments per week

    LLM inference ≤ 3s with retries/failure handling


Tech Stack:

    AI Platforms: OpenAI, Hugging Face, LangChain

    Frameworks: FastAPI, Flask, SQLAlchemy

    Databases: PostgreSQL, Redis, Pinecone, Qdrant

    DevOps: Docker, GitHub Actions, Terraform

    Monitoring: Prometheus, Grafana, Sentry

    Collaboration: Slack, Notion, ChatGPT



    View all jobs Visit website 

Powered by


```